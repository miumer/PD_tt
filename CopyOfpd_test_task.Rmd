---
title: "Pipedrive test task"
author: "Siim PÃµldre"
date: "5 5 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(psych)
library(kableExtra)
library(patchwork)
library(pheatmap)
library(reticulate)
library(scales)
```

TRY TO AUTOMAICALLY ACCESS FILE FROM KAGGLE.

1)Data tranformations
2)General descriptives
3)Logistic regression on raw data
4)Clustering and cluster analsys (how clusters differ + logistic regression using clusters with baseline)
5)XGBoost and feature analysis

I chose a dataset from kaggle that deals with a broadband companies churn. The dataset is from january 2020. I chose this specific dataset firstly because of its content. It is a subscription based service that offers several packages(Bandwidth) and has to deal with churn. This is similar to the types of data Pipedrive deals with and churn is a problem in any company. Secondly the features have nice metadata so i understand more clearly what i am looking at. The inconvenience with this dataset is that each customer has a row for each month they are a customer (~500k rows) but for most of the analysis i am planning to do it is better to have the data in a format where each customer has one row. For this i have to transform the whole dataset.
```{r}
churn_tr <- read.csv("bbs_cust_base_scfy_20200210.csv", header = TRUE)
```

There are some missing values but for two features the percentages are very low (under 1%) so they are not probably a major cause for concern when we remove these lines.
```{r}
Puuduvad <- churn_tr %>% 
  summarise_all(funs(sum(is.na(.)))) %>% 
  pivot_longer(everything(), names_to = "Feature", values_to = "Missing") 

Puuduvad %>% 
  mutate(Prop.missing = round(`Missing`/nrow(churn_tr),4)) %>%
  filter(Missing > 0) %>% 
  arrange(., desc(Missing)) %>% 
  kbl() %>% 
  kable_styling()

churn_tr <- churn_tr %>% 
  drop_na()
```

There are:  
- 14 categorical variables  
- 5 integers (more caution in interpreting descriptives as numeric)
- 1 numeric variables

The data has ~510k rows and 20 columns. Secured revenue is the only numeric/float variable. I will treat image and contract month as categorical variables (altho they are ordinal). Image because it is actually a date variable about billing month and contract month because it has a more categorical character being a contract type or category.
```{python}
r.churn_tr.info()
```

Looking at variables to see if some have 0 variance to remove them:
1) bill_cycl has no variance so we don't need that variable (labeled as ignorable in the data source too)
2)serv_type also has only one value(BBS)
```{r}
churn_tr %>%
  lapply(unique) %>% 
  lapply(length)
```

Some variables are not explained and just said that they can be ignored. I will remove some of them here. Two of them have 0 variance as said. One i just don't understand. I will retain one called serv_code which seems to show the service a client is on. I will aggregate this to show how many different services a client has used. 
```{r}
churn_tr <- churn_tr %>% 
  select(-bill_cycl & -serv_type & -line_stat) #getting rid of variable with no variance
```

Putting the dataset in more workable format and doing some feature engineering below. Some notes:  
1) Removing customers who passed away
2) Tenure in the dataset is based on "time in system". So for a person who signs up, tenure could allready be anything. I expect the customer is always deleted from the system after churn to calculate tenure.
3) I will use average secured revenue per month for each client
4) I will use average complaints per month for each client
5) I Will not use variables image, contract dates (features extracted from them are used), current_mth_churn, because they don't seem to give any additional information
```{r}
churn_oc <- churn_tr %>%
  filter(complaint_cnt %in% c("0","1", "2", "3", "4", "5", "6", "7")) %>% 
  mutate(complaint_cnt = as.numeric(complaint_cnt)) %>% 
  group_by(newacct_no) %>%
  summarise(churn = first(churn), #is churned or not
            term_read_code = last(term_reas_code), #termination reason code
            term_reas_desc = last(term_reas_desc), #termination reason description
            diff_servs = n_distinct(serv_code), #number of different services used
            tenure = (max(tenure)-min(tenure)), #Tenure
            contract_month = first(contract_month), #contract length
            ce_expiry = first(ce_expiry), #ifference between contract and jan 2020
            secured_revenue = mean(secured_revenue), #average revenue
            last_band = last(bandwidth), #last known bandwidth
            complaint_avg = mean(complaint_cnt), #average complaints per month
            phone_serv = last(with_phone_service)) %>% #Last info about using phone service
  ungroup() %>% 
  select(-newacct_no) #Getting rid of customer identifier
```

We are left with a dataset of roughly 27k unique customers and 11 features.  
2 floats,  
4 integers  
5 objects
```{python}
r.churn_oc.info()
```

Percentage of people churned is a lot lower so a lot of class imbalance.
```{r}
churn_oc %>% 
  ggplot(aes(x = churn, fill = churn)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) + 
  scale_y_continuous(labels = percent) +
  geom_text(aes(y = ((..count..)/sum(..count..)), label = scales::percent((..count..)/sum(..count..))), stat = "count", vjust = -0.25) +
  theme_minimal()+
  theme(axis.text.y=element_blank(), 
        axis.ticks=element_blank(),
        axis.title.y=element_blank(),
        legend.position = "none")+
  scale_fill_brewer(palette = "Dark2")
```


Some observations from descriptive statistics:
1) Most people have used 1 - 2 services
2) Average tenure is around 17.54 with median at 23. For 50% of people its between 12 and 23
3) Contracts expire on average in 5.8 months (can also be negative if expired before jan 2020)
4) Average secured revenue per month is 550 on average with a median on 226. It is highly skewed.
5) Average number of complaints per month is 0 but maximum is 5 (while actual maximum complaints in a single month is 7)
```{r}
churn_oc %>%
  select_if(~class(.) != 'character') %>%
  describe(., IQR = TRUE,quant = c(.25, .75)) %>%
  kbl() %>% 
  kable_styling()
```

From visual assessment we can see that: 
1)people not using a phone service are more likely to churn
2)people using lower bandwidth packages are more likely to churn
```{r}
churn_oc %>%
  select(-term_read_code, -term_reas_desc) %>%  #uninformative variables in this case
  select_if(~class(.) == 'character') %>%
  pivot_longer(!churn, names_to = c("feature"), values_to = c("value")) %>% 
  ggplot(aes(x = value, fill = churn))+
  geom_bar(position = "fill") +
  theme_minimal()+
  coord_flip()+
  scale_fill_brewer(palette = "Dark2")+
  facet_wrap(~feature, scales = "free")+
  labs(title = "Relationship between churn and some categorical variables")
```

Comparing churned and not churned people there are some visual differences:  
1) There is a difference in contract expiry which is logical because a lot of people who have churned have done so because of contract expiring and people who have not churned have their contract dates more further into the future.  
2) Contract month is heavily centered around 24 months but there are some other types of contracts
3) Secured revenue median seems to be higher among people who have churned while the 50% of people around that median are slightly more spread out. But People who have not churned have higher maximum revue.
4)7758 people have revenue of 0 and were excluded.
5)Median tenure is lower among people who have churned and the distribution is denser around that median
```{r}
churn_oc %>%
  select_if(~class(.) != 'character')%>%
  cbind(churn_oc %>% select(churn)) %>%
  mutate(secured_revenue = log(secured_revenue)) %>% #log transforming the revenue
  pivot_longer(!churn, names_to = c("feature"), values_to = c("value")) %>%
  ggplot(aes(x = churn, fill = churn, y = value))+
  geom_boxplot() + 
  theme_minimal()+
  scale_fill_brewer(palette = "Dark2")+
  facet_wrap(~feature, scales = "free", nrow = 1)+
  labs(title = "Distributions for continuous")
```

Below is a general look at selected categorical variables. Some were left out because in the form they are in they don't give any information about relationship with churn on this type of plot. Some observations from looking at these plots:
1) People with lower bandwidth churned more. This variable could be made numeric. Also FTTO could be concidered separately because it is a separate type of service.
1) serv_type has no variation (everything is BBS) so can be gotten rid of.
2) People on phone service have churned less than people without phone service
3) People with the highest complaint count (at 7 and 6) don't churn
4) People with phone service labeled O (not sure what this means...other maybe) haven't churned
5) Not sure what variable X stands for and it is not explained in the metadata but people with X as Y have 0 churn. 
```{r fig.height=7, fig.width=10}
churn_tr %>%
  select_if(~class(.) == 'character') %>%
  select(-newacct_no & -effc_strt_date & -effc_end_date & -serv_code & -term_reas_code & -term_reas_desc) %>%
  pivot_longer(!churn, names_to = c("feature"), values_to = c("value")) %>% 
  ggplot(aes(x = value, fill = churn))+
  geom_bar(position = "fill") +
  theme_minimal()+
  coord_flip()+
  scale_fill_brewer(palette = "Dark2")+
  facet_wrap(~feature, scales = "free")+
  labs(title = "Relationship between churn and some categorical variables")
```

Some feature engineering based on previous observations:
1) Getting rid of variable with no variance and also variables that imply churn allready (termination reason etc).
2) Also getting rid of contract date variables because a lot of info about them is allready in expiry date and contract length. These could be further extrapolated to generate new variables like wether contract expiry season makes a difference or public holiday but i will not do this here.
3) There is somewhat of a problem with bandwidth variable because FTTO is a totally different type of bandwidth package so the variable can't be used as an ordinal variable with two different types of bandwidth packages. Options that come to mind are:
- Use as categorical variable
- Do separate analysis for the two types of bandwidth packages
4) 
```{r}
#get rid of uninformative features
churn_tr <- churn_tr %>% 
  select(-newacct_no &-serv_type & -term_reas_code & -term_reas_desc & -effc_strt_date & -effc_end_date & -current_mth_churn)

#New feature to show if FTTO bandwidth package or not
churn_tr <- churn_tr %>% 
  mutate(is_ftto = case_when(
    str_detect(bandwidth, "FTTO") ~ "Y",
               TRUE ~ "N") 
  )


```


```{python}
import numpy as np 
import pandas as pd 
import seaborn as sns 
import matplotlib.ticker as mtick 
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
import matplotlib.cm as cm
from sklearn.preprocessing import normalize
import xgboost as xgb
from sklearn.model_selection import train_test_split
from xgboost import plot_importance

plt.style.use('ggplot')
```

```{python}
churn_pd = pd.read_csv("bbs_cust_base_scfy_20200210.csv")
churn_pd.dropna(inplace=True)
churn_pd2 = churn_pd.iloc[:,1:]
churn_pd2['Churn'].replace(to_replace='Yes', value=1, inplace=True)
churn_pd2['Churn'].replace(to_replace='No',  value=0, inplace=True)
```

```{python}
churn_pd.info()
```


```{python}
churn_dummies = pd.get_dummies(churn_pd2.loc[:,churn_pd2.columns != 'ServiceArea'])
```

```{python}
plt.figure(figsize=(16,16))
plt.style.use('ggplot')
my_cmap = cm.get_cmap('Accent')
churn_corr = churn_dummies.corr()['Churn'].sort_values(ascending = False)
churn_corr.iloc[1:].plot(kind='barh', cmap=my_cmap)

plt.title('Correlation with churn',fontsize=20)
plt.xlabel('correlation', fontsize=13)
plt.ylabel('feature',fontsize=13)

plt.tight_layout()
plt.xticks(fontsize = 15) 
plt.yticks(fontsize = 12) 
plt.grid(True)
plt.show() 
```
```{python}
churn_dummies[pd.DataFrame(churn_corr[(churn_corr > 0.01) | (churn_corr < -0.01)]).index.values].info()
```

```{python}
features = churn_dummies[pd.DataFrame(churn_corr[(churn_corr > 0.01) | (churn_corr < -0.01)]).index.values].columns.values

scaler  = MinMaxScaler(feature_range=(0,1))

scaler.fit(churn_dummies[pd.DataFrame(churn_corr[(churn_corr > 0.01) | (churn_corr < -0.01)]).index.values]) 

churn_dummies = pd.DataFrame(scaler.transform(churn_dummies[pd.DataFrame(churn_corr[(churn_corr > 0.01) | (churn_corr < -0.01)]).index.values])) 

churn_dummies.columns = features
```

```{python}
y = churn_dummies['Churn'].values
x = churn_dummies.drop(columns = ['Churn'])

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
```

```{python}
xgb_model = xgb.XGBClassifier(max_depth=5, gamma = 0.1 , learning_rate=0.08, objective= 'binary:logistic',n_jobs=-1, random_seed=0).fit(x_train, y_train)

prediction_testx = xgb_model.predict(x_test)

print('Accuracy of XGB classifier on training set: {:.2f}'
       .format(xgb_model.score(x_train, y_train)))

print('Accuracy of XGB classifier on test set: {:.2f}'
       .format(xgb_model.score(x_test[x_train.columns], y_test)))
```

```{python}
fig, ax = plt.subplots(figsize=(10,8))
plot_importance(xgb_model, ax=ax);
plt.tight_layout()
plt.show()
```

